[{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'set'\nrequire 'objspace'\nrequire 'concurrent'\n\ndef run_benchmark(x)\n  results = {}\n  memory_usage = {}\n  \n  Benchmark.bm(20) do |bm|\n    hash = Hash.new\n    set = Set.new\n    weak_map = ObjectSpace::WeakMap.new\n    concurrent_map = Concurrent::Map.new\n\n    # Benchmark and measure memory for each data structure\n    [\n      [:hash, hash], [:set, set], [:weak_map, weak_map], [:concurrent_map, concurrent_map]\n    ].each do |name, structure|\n      GC.start # Force garbage collection before measurement\n      initial_memory = ObjectSpace.memsize_of(structure)\n\n      results[:\"#{name}_write\"] = bm.report(\"#{name.to_s.capitalize} write:\") do\n        x.times do |i|\n          case structure\n          when Set\n            structure.add(i)\n          else\n            structure[i] = i\n          end\n        end\n      end\n\n      results[:\"#{name}_read\"] = bm.report(\"#{name.to_s.capitalize} read:\") do\n        x.times do |i|\n          case structure\n          when Set\n            structure.include?(i)\n          else\n            structure.key?(i)\n          end\n        end\n      end\n\n      GC.start # Force garbage collection after operations\n      final_memory = ObjectSpace.memsize_of(structure)\n      memory_usage[name] = final_memory - initial_memory\n    end\n  end\n\n  puts \"\\nResults Table:\"\n  puts \"| Data Structure | Read (ops/s) | Write (ops/s) | Memory Usage (bytes) |\"\n  puts \"|----------------|--------------|---------------|----------------------|\"\n  [\n    [\"Hash\", :hash_read, :hash_write, :hash],\n    [\"Set\", :set_read, :set_write, :set],\n    [\"WeakMap\", :weak_map_read, :weak_map_write, :weak_map],\n    [\"ConcurrentMap\", :concurrent_map_read, :concurrent_map_write, :concurrent_map]\n  ].each do |name, read_key, write_key, mem_key|\n    read_ops = (x / results[read_key].total).round(2)\n    write_ops = (x / results[write_key].total).round(2)\n    mem_usage = memory_usage[mem_key]\n    puts \"| #{name.ljust(14)} | #{read_ops.to_s.ljust(12)} | #{write_ops.to_s.ljust(13)} | #{mem_usage.to_s.ljust(20)} |\"\n  end\nend\n\nrun_benchmark(10_000)"},{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'json'\nrequire 'oj'\n\ndef build_complex_hash(depth = 3)\n  {\n    name: \"Person#{rand(1000)}\",\n    age: rand(18..80),\n    address: {\n      street: \"#{rand(1000)} Main St\",\n      city: [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      country: [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      postal_code: \"#{rand(10000..99999)}\"\n    },\n    hobbies: [\n      {\n        name: \"Reading\",\n        years_practiced: rand(1..20),\n        skill_level: rand(1..10)\n      },\n      {\n        name: \"Cycling\",\n        years_practiced: rand(1..15),\n        skill_level: rand(1..10)\n      },\n      {\n        name: \"Cooking\",\n        years_practiced: rand(1..10),\n        skill_level: rand(1..10)\n      }\n    ],\n    metadata: {\n      created_at: Time.now - rand(10000000),\n      updated_at: Time.now,\n      version: \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      tags: [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    },\n    friends: depth > 0 ? [build_complex_hash(depth - 1), build_complex_hash(depth - 1)] : []\n  }\nend\n\nAddress = Data.define(:street, :city, :country, :postal_code)\nHobby = Data.define(:name, :years_practiced, :skill_level)\nMetadata = Data.define(:created_at, :updated_at, :version, :tags)\nPerson = Data.define(:name, :age, :address, :hobbies, :metadata, :friends)\n\nAddressStruct = Struct.new(:street, :city, :country, :postal_code)\nHobbyStruct = Struct.new(:name, :years_practiced, :skill_level)\nMetadataStruct = Struct.new(:created_at, :updated_at, :version, :tags)\nPersonStruct = Struct.new(:name, :age, :address, :hobbies, :metadata, :friends)\n\nclass Auto\n  def initialize(attributes={})\n    attributes.each do |key, value|\n      instance_variable_set(\"@#{key}\", value)\n\n      define_singleton_method(key) do\n        instance_variable_get(\"@#{key}\")\n      end\n    end\n  end\nend\n\ndef build_data_object(depth = 3)\n  Person.new(\n    \"Person#{rand(1000)}\",\n    rand(18..80),\n    Address.new(\n      \"#{rand(1000)} Main St\",\n      [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      \"#{rand(10000..99999)}\"\n    ),\n    [\n      Hobby.new(\"Reading\", rand(1..20), rand(1..10)),\n      Hobby.new(\"Cycling\", rand(1..15), rand(1..10)),\n      Hobby.new(\"Cooking\", rand(1..10), rand(1..10))\n    ],\n    Metadata.new(\n      Time.now - rand(10000000),\n      Time.now,\n      \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    ),\n    depth > 0 ? [build_data_object(depth - 1), build_data_object(depth - 1)] : []\n  )\nend\n\ndef build_struct_object(depth = 3)\n  PersonStruct.new(\n    \"Person#{rand(1000)}\",\n    rand(18..80),\n    AddressStruct.new(\n      \"#{rand(1000)} Main St\",\n      [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      \"#{rand(10000..99999)}\"\n    ),\n    [\n      HobbyStruct.new(\"Reading\", rand(1..20), rand(1..10)),\n      HobbyStruct.new(\"Cycling\", rand(1..15), rand(1..10)),\n      HobbyStruct.new(\"Cooking\", rand(1..10), rand(1..10))\n    ],\n    MetadataStruct.new(\n      Time.now - rand(10000000),\n      Time.now,\n      \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    ),\n    depth > 0 ? [build_data_object(depth - 1), build_data_object(depth - 1)] : []\n  )\nend\n\ndef run_benchmark(iterations)\n  results = {\n    creation: {},\n    serialization: {},\n    deserialization: {}\n  }\n\n  Benchmark.bm(25) do |bm|\n    # Object creation benchmarks\n    results[:creation][:complex_hash] = bm.report(\"Create complex hash:\") do\n      iterations.times { build_complex_hash }\n    end\n\n    results[:creation][:data_object] = bm.report(\"Create Data object:\") do\n      iterations.times { build_struct_object }\n    end\n\n    # Pre-generate objects and strings for other benchmarks\n    complex_hash = build_complex_hash\n    data_object = build_struct_object\n    \n    json_hash_string = JSON.generate(complex_hash)\n    oj_hash_string = Oj.dump(complex_hash,  mode: :object)\n    oj_data_string = Oj.dump(data_object, mode: :object)\n    marshal_hash_string = Marshal.dump(complex_hash)\n    marshal_data_string = Marshal.dump(data_object)\n    json_data_string = oj_data_string\n\n\n    # Serialization benchmarks\n    results[:serialization][:json_hash] = bm.report(\"JSON.generate(hash):\") do\n      iterations.times { JSON.generate(complex_hash) }\n    end\n\n    results[:serialization][:oj_hash] = bm.report(\"Oj.dump(hash):\") do\n      iterations.times { Oj.dump(complex_hash) }\n    end\n\n    results[:serialization][:marshal_hash] = bm.report(\"Marshal.dump(hash):\") do\n      iterations.times { Marshal.dump(complex_hash) }\n    end\n\n    results[:serialization][:json_data] = bm.report(\"JSON.generate(Data.object):\") do\n      iterations.times { JSON.generate(data_object) }\n    end\n\n    results[:serialization][:oj_data] = bm.report(\"Oj.dump(Data.object):\") do\n      iterations.times { Oj.dump(data_object) }\n    end\n\n    results[:serialization][:marshal_data] = bm.report(\"Marshal.dump(Data.object):\") do\n      iterations.times { Marshal.dump(data_object) }\n    end\n\n    # Deserialization benchmarks\n    results[:deserialization][:json_hash] = bm.report(\"JSON.parse(hash):\") do\n      iterations.times { JSON.parse(json_hash_string) }\n    end\n\n    results[:deserialization][:oj_hash] = bm.report(\"Oj.load(hash):\") do\n      iterations.times { Oj.load(oj_hash_string,  mode: :object) }\n    end\n\n    results[:deserialization][:marshal_hash] = bm.report(\"Marshal.load(hash):\") do\n      iterations.times { Marshal.load(marshal_hash_string) }\n    end\n\n    results[:deserialization][:json_data] = bm.report(\"JSON.parse(Data.object):\") do\n      iterations.times { JSON.parse(json_data_string) }\n    end\n\n    results[:deserialization][:oj_data] = bm.report(\"Oj.load(Data.object):\") do\n      iterations.times { Oj.load(oj_data_string,  mode: :object) }\n    end\n\n    results[:deserialization][:marshal_data] = bm.report(\"Marshal.load(Data.object):\") do\n      iterations.times { Marshal.load(marshal_data_string) }\n    end\n  end\n\n  print_results(results, iterations)\nend\n\ndef print_results(results, iterations)\n  [:creation, :serialization, :deserialization].each do |category|\n    puts \"\\n#{category.to_s.capitalize} Results:\"\n    puts \"| Method | Operations/second |\"\n    puts \"|--------|-------------------|\"\n    results[category].each do |key, result|\n      ops_per_second = (iterations / result.total).round(2)\n      puts \"| #{key.to_s.ljust(20)} | #{ops_per_second.to_s.ljust(17)} |\"\n    end\n  end\nend\n\nrun_benchmark(1000)"},{"kind":2,"language":"ruby","value":"class Auto\n  def initialize(attributes={})\n    attributes.each do |key, value|\n      value = Auto.new(value) if value.is_a?(Hash)\n      value = value.map { |v| v.is_a?(Hash) ? Auto.new(v) : v } if value.is_a?(Array)\n      instance_variable_set(\"@#{key}\", value)\n\n      define_singleton_method(key) do\n        instance_variable_get(\"@#{key}\")\n      end\n    end\n  end\nend\n\ndata = {\n  name: \"John\",\n  age: 30,\n  address: {\n    street: \"123 Main St\",\n    city: \"Anytown\"\n  },\n  hobbies: [\n    { name: \"reading\", years: 10 },\n    { name: \"cycling\", years: 5 }\n  ]\n}\n\nauto = Auto.new(data)\n\nputs auto.name  # \"John\"\nputs auto.age   # 30\nputs auto.address.street  # \"123 Main St\"\nputs auto.hobbies[0].name  # \"reading\"\n\n# Convert back to hash\nhash = auto.to_h\nputs hash  # Prints the entire hash structure"},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":"def transform_keys(obj, transform_map)\n  return obj if transform_map.nil?\n  puts \"obj: #{obj}, transform_map: #{transform_map}\"\n  case obj\n  when Hash\n    obj.each_with_object({}) do |(key, value), result|\n      new_key = transform_map[key] || key\n      if new_key.is_a?(Symbol)\n        result[new_key] = value\n      else\n        result[key] = transform_keys(value, transform_map[key])\n      end\n    end\n  when Array\n    obj.map { |item| transform_keys(item, transform_map) }\n  else\n    obj\n  end\nend\nobj = {\n  item_type: { id: [\"change_event_line_item\"] },\n  with_commitment: [{ contract_line_item_id: [370, 374]}, {none: true}, {pco_line_item_id: :lol}, {some_test: :bot }]\n\n}\n\nts_keys = {\n  change_event_line_item: :id,\n  with_change_event_ids: :event_id,\n  with_commitment: {\n    contract_line_item_id: :commitment_contract_line_item_id,\n    pco_line_item_id: :commitment_potential_change_order_line_item_id,\n    none: :without_committed_cost\n  }\n}.freeze\n\nresult = transform_keys(obj, ts_keys)\n"},{"kind":2,"language":"ruby","value":"   def commitment(values, scope)\n      puts \"commitment: #{scope}, values: #{values}\"\n   end\n\n   def query_on_scope_field?(filter)\n    puts \"query_on_scope_field?: #{filter}\"\n    puts     filter.class\n\n    filter == :commitment\n   end\n\n   def use_service_method?(filter)\n    puts \"use_service_method?: #{filter}\"\n    respond_to?(filter, true)\n   end\n\n   def service_method(scope, (field, values))\n    send(field, values, scope)\n   end\n\n   def run_query_on_scope(scope, *args)\n    puts \"run_query_on_scope: #{scope}, #{args}\"\n   end\n\n   pr = proc do |*args|\n                puts  \"args: #{args}\"\n                case args\n                in [_, [Symbol => filter, _]] if query_on_scope_field?(filter) then run_query_on_scope(*args)\n                in [_, [Symbol => filter, _]] if use_service_method?(filter) then service_method(*args)\n                in [_, [Hash, _]] then filter_to_query[*args]\n                else raise ArgumentError, \"Unknown filter: #{filter}\"\n                end\n              end\n\n              {commitment: [line_item: [1,2,3,34]]}.reduce(1, &pr)\n\n              pr.call()\n\n"},{"kind":2,"language":"ruby","value":"require 'securerandom'\nrequire 'date'\nkeys = [:\"change_event.number_title\", :\"change_event.title\", :\"change_event.number\", :\"change_event.status\", :\"change_event.scope\", :\"change_event.type\", :\"change_event.change_reason\", :\"change_event.origin.name\", :\"change_event.created_at\", :\"change_event.created_by\", :item_type, :\"budget_code.description\", :description, :\"vendor.name\", :\"contract.name\", :unit_of_measure, :aging, :\"revenue.quantity\", :\"revenue.unit_cost\", :\"revenue.rom\", :\"revenue.prime_potential_change_order.amount\", :\"revenue.prime_potential_change_order.title\", :\"revenue.stage.display_value\", :\"revenue.days_in_stage\", :\"revenue.stage_status\", :\"revenue.in_status_since\", :\"revenue.latest_price\", :\"cost.quantity\", :\"cost.unit_cost\", :\"cost.rom\", :\"cost.request_for_quote.amount\", :\"cost.request_for_quote.title\", :\"cost.commitment.amount\", :\"cost.commitment.title\", :\"cost.non_commitment\", :\"cost.stage.display_value\", :\"cost.days_in_stage\", :\"cost.stage_status\", :\"cost.in_status_since\", :\"cost.latest_cost\", :over_under, :\"budget.quantity\", :\"budget.unit_cost\", :\"budget.rom\", :\"budget.budget_change.amount\", :\"budget.stage.display_value\", :\"budget.days_in_stage\", :\"budget.stage_status\", :\"budget.in_status_since\", :\"budget.impact_amount\", :\"budget.modification.amount\", :\"production_quantity.quantity\", :\"production_quantity.unit_of_measure\"]\nCeliStruct = Data.define(*keys)\n\ndef generate_random_value(key)\n  case key.to_s\n  when /number|quantity|amount|rom|days/\n    rand(1..1000)\n  when /cost|price/\n    rand(100.0..10000.0).round(2)\n  when /_at$/\n    DateTime.now - rand(365)\n  when /status|type|scope|reason|stage/\n    %w[New In-Progress Completed Approved Rejected].sample\n  when /name|title|description/\n    SecureRandom.alphanumeric(10)\n  else\n    SecureRandom.uuid\n  end\nend\n\n# Create a hash with random values for each key\nrandom_data = -> { keys.to_h { |key| [key, generate_random_value(key)] } }\n\n# Create an instance of CeliStruct with the random data\ndata = (0..87_000).map { CeliStruct.new(**random_data.call) }; 0\n"},{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'json'\nrequire 'oj'\n\ndef create_flat_data(depth = 3, prefix = '')\n  result = {}\n  (1..5).each do |i|\n    key = \"#{prefix}key#{i}\"\n    result[key] = \"value#{i}\"\n    if depth > 0\n      result.merge!(create_flat_data(depth - 1, \"#{key}.\"))\n    end\n  end\n  result\nend\n\ndef create_nested_data(depth = 3)\n  result = {}\n  (1..5).each do |i|\n    key = \"key#{i}\"\n    if depth > 0\n      result[key] = create_nested_data(depth - 1)\n    else\n      result[key] = \"value#{i}\"\n    end\n  end\n  result\nend\n\ndef flat_to_nested(flat_data)\n  result = {}\n  flat_data.each do |key, value|\n    parts = key.to_s.split('.')\n    current = result\n    parts[0...-1].each do |part|\n      current[part] = {} unless current[part].is_a?(Hash)\n      current = current[part]\n    end\n    current[parts.last] = value\n  end\n  result\nend\n\ndef nested_to_flat(nested_data, prefix = '')\n  result = {}\n  nested_data.each do |key, value|\n    new_key = prefix.empty? ? key : \"#{prefix}.#{key}\"\n    if value.is_a?(Hash)\n      result.merge!(nested_to_flat(value, new_key))\n    else\n      result[new_key] = value\n    end\n  end\n  result\nend\n\nflat_data = create_flat_data\nnested_data = create_nested_data\n\nn = 10_000\n\nBenchmark.bm(20) do |x|\n  x.report(\"Flat merge:\") { n.times { flat_data.merge(create_flat_data) } }\n  x.report(\"Nested merge:\") { n.times { nested_data.merge(create_nested_data) } }\n  \n  x.report(\"Flat to nested:\") { n.times { flat_to_nested(flat_data) } }\n  x.report(\"Nested to flat:\") { n.times { nested_to_flat(nested_data) } }\n  \n  x.report(\"Flat deep copy:\") { n.times { Oj.load(Oj.dump(flat_data)) } }\n  x.report(\"Nested deep copy:\") { n.times { Oj.load(Oj.dump(nested_data)) } }\n  \n  x.report(\"Flat serialize:\") { n.times { Oj.dump(flat_data) } }\n  x.report(\"Nested serialize:\") { n.times { \n  Oj.dump(nested_data) } }\nend"},{"kind":2,"language":"ruby","value":"require 'open-uri'\nuri = \"https://pz01.application.procoretech-qa.com/fas/api/v5/files/us-east-1/pro-core.com-staging/prostore/20181006001613_staging9_9468.xfd?companyId=1&callerServiceName=Procore&createdAt=1721238586&expiresAt=1721238646&userId=5&sig=0db1ee5064493463dac180ecc32e7cf9f639dff745e71df3156a049f6217b280\"\n\n# URI(uri).read\nbegin\n  URI(uri).read\nrescue OpenURI::HTTPError => e\n  puts e.message\n  \nend\n"},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":"require 'dry/equalizer'\n\nclass Man\n  include Dry::Equalizer(:first, :last)\n\n  attr_reader :first, :last\n\n  def initialize(latitude, longitude)\n    @first, @last = latitude, longitude\n  end\nend\n\nman1 = Man.new(\"John\", \"Doe\")\nman2 = Man.new(\"John\", \"Doe\")\n\nstore = {}\nstore[man1] = true\nputs store[man2] \n\n"},{"kind":2,"language":"ruby","value":"a, b = *{test: :best}\nputs a\nputs b\n\na, b = *{test: [1,2,34]}\n"},{"kind":2,"language":"ruby","value":"class Events < Relations[:sql]\n  associte do \n    has_many :celis\n    belongs_to :change_reason\n  end\nend\n\nclass ChangeReason < Relations[:sql]\n  associte do \n    has_many :events\n    belogns_to :change_status\n  end\nend\n\nclass ChangeStatus < Relations[:sql]\n  associte do \n    has_many :change_reasons\n  end\nend\n\nclass Celi < Relations[:sql]\n  associte do \n    belongs_to :event\n    belongs_to :line_item\n  end\nend\n\nclass LineItem < Relations[:service]\n  associte do \n    has_one :celi\n  end\nend\n\nclass Order < Relations[:service]\n  associte do \n    has_many :line_items\n    belongs_to :stage\n  end\nend\n\nclass Stage < Relations[:service]\n  associte do \n    has_many :orders\n  end\nend\n"},{"kind":1,"language":"markdown","value":"```ruby\nevents = Events.new.joins(:celis. change_reason: :status) \nevents.dataset \n```\n\n```ruby\n< Sql::Dataset\n  datasource: ArModel,\n  joins: [\n    {\n      rel_name: :celis,\n      dataset: CeliDs, \n      join_keys: {event_id: :id}\n    }, \n    [\n      {\n        rel_name: :orders, \n        dataset: ChangeOrderDs, \n        join_keys: {order_id: :id}\n      },\n      [\n        {\n          rel_name: :change_reason,\n          dataset: ChangeReasonDs,\n          join_keys: {change_reason_id: :id}\n        },\n        {\n          rel_name: :change_status,\n          dataset: ChangeStatusDs,\n          join_keys: {change_status_id: :id}\n        }\n      ]\n    ], \n  ],\n  where: { status: \"open\", celis: { amount.gt(100) }, change_orders: {stage: 'closed'} }\n>\n\nevents_graph = event.to_graph \nevents_graph.dataset \n\nGraph<\n  dataset: <EventsDataset:inst>\n  nodes: [\n    Graph<rel_name: :celis, dataset: CeliDs, join_keys: { event_id: :id }, nodes: [\n      Graph<rel_name: :orders, dataset: OrdersDs, join_keys: { order_id: :id }, nodes: [\n        Graph<rel_name: :change_reason, dataset: ChangeReasonDs, join_keys: { change_reason_id: :id }, nodes: [\n          Graph<rel_name: :change_status, dataset: ChangeStatusDs, join_keys: { change_status_id: :id }, nodes: []>,\n        ]>,\n      ]>,\n    ]>,\n  ]\n>\n```"},{"kind":2,"language":"ruby","value":"def test(*args)\n  args.reduce([]) do |acc, (key, value)|\n    puts \"key: #{key}, value: #{value}\"\n    acc << key if value\n    acc\n  end\nend\n\ntest(:a, b: 2, c: [1,2], d: {e: :g})"},{"kind":2,"language":"ruby","value":" def joins(args, type=:inner)\n    puts \"args: #{args}, type: #{}, kwargs: #}\"\n end\n \n\n joins(:haga,{test: 1}, lol: 2, orders: [:reason, status: { change: :type }])\n"},{"kind":2,"language":"ruby","value":"some_block = ->{ dd }\n\nclass Test \n  def self.dd\n     puts 'loool'\n  end\nend.then do |klass|\n  Test.instance_exec(&some_block)\nend"},{"kind":2,"language":"ruby","value":""},{"kind":1,"language":"markdown","value":"# Resources Library Documentation\n\n## Overview\n\nThe Resources library is a powerful and flexible data handling solution designed to simplify complex data operations across various data sources. It provides a unified interface for working with both SQL and service-based data, allowing developers to build sophisticated queries and relationships with ease.\n\n### Key Features\n\n1. **Unified Data Interface**: Seamlessly work with SQL databases and external services using a consistent API.\n\n2. **Advanced Association Handling**: Define and navigate complex relationships between different data entities.\n\n3. **Flexible Query Building**: Construct complex queries with support for joins, filtering, sorting, and aggregations.\n\n4. **Cross-Adapter Operations**: Perform joins and other operations across different data sources (e.g., SQL and service-based).\n\n5. **Performance Optimized**: Designed for efficient handling of large datasets and complex queries.\n\n6. **Extensible Architecture**: Easily extend the library with new adapters or functionalities.\n\n7. **Type-Safe Operations**: Leverage Ruby's type system for safer data handling.\n\n### Unique Perspective\n\nUnlike traditional ORMs or data mappers, the Resources library takes a more holistic approach to data handling:\n\n- It doesn't just map objects to database tables but provides a flexible way to define and work with data from any source.\n- The library allows for complex operations across different data adapters, enabling powerful data aggregation and analysis capabilities.\n- It emphasizes a declarative style of defining relationships and queries, promoting cleaner and more maintainable code.\n\n## Main Interface and Architecture Design\n\nThe Resources library is built on a modular architecture that promotes flexibility and extensibility. Here's an overview of the main components and their interactions:\n\n### Core Components\n\n1. **Relation**: The central concept, representing a queryable set of data.\n   ```ruby\n   class User < Resources::Relation\n     # ...\n   end\n   ```\n\n2. **Dataset**: Represents the actual data source (e.g., SQL table, external service).\n   ```ruby\n   class SqlDataset < Resources::Dataset\n     # ...\n   end\n   ```\n\n3. **Associations**: Define relationships between different relations.\n   ```ruby\n   class User < Resources::Relation\n     associate do\n       has_many :posts\n       belongs_to :company\n     end\n   end\n   ```\n\n4. **Query Methods**: Methods for building and executing queries.\n   ```ruby\n   User.new(context: context)\n       .where(name: /John/)\n       .join(relation: Post, join_keys: { id: :user_id })\n       .order(name: :asc)\n       .limit(10)\n       .to_a\n   ```\n\n### Architecture Diagram\n\n```mermaid\ngraph TD\n    A[Client Code] --> B[Relation]\n    B --> C[Dataset]\n    B --> D[Associations]\n    C --> E[SQL Adapter]\n    C --> F[Service Adapter]\n    D --> G[Has Many]\n    D --> H[Belongs To]\n    D --> I[Has One Through]\n```\n\n### Key Design Decisions\n\n1. **Separation of Concerns**: Clear separation between relation definitions, query building, and data retrieval.\n\n2. **Adapter Pattern**: Use of adapters for different data sources, allowing easy extension to new types of data stores.\n\n3. **Composable Queries**: Query methods that return new relation instances, enabling method chaining and composition.\n\n4. **Lazy Evaluation**: Queries are built up and only executed when data is actually needed.\n\n5. **Flexible Association Definitions**: Associations can be defined declaratively and work across different adapters.\n\n### Module Interactions\n\n- **Relation** interacts with **Dataset** to execute queries.\n- **Associations** enhance **Relation** with relationship navigation capabilities.\n- **Query Methods** in **Relation** build up a query that is eventually executed by the **Dataset**.\n- **Adapters** (SQL, Service) provide the actual implementation for data retrieval and manipulation.\n\nThis architecture allows for a high degree of flexibility and extensibility, enabling the library to handle a wide range of data handling scenarios while maintaining a consistent and intuitive interface for developers.\n\nCertainly! I'll add more examples of usage and include a note about the next steps for mapping and composing items with schemas. Here's the additional content:\n\n## Usage Examples\n\nLet's explore some more detailed examples of how to use the Resources library in various scenarios:\n\n### 1. Complex Querying Across Multiple Relations\n\n```ruby\nclass Order < Resources::Relation[:sql]\n  associate do\n    belongs_to :customer\n    has_many :line_items\n    has_one :invoice\n  end\nend\n\nclass Customer < Resources::Relation[:sql]\n  associate do\n    has_many :orders\n  end\nend\n\nclass LineItem < Resources::Relation[:sql]\n  associate do\n    belongs_to :order\n    belongs_to :product\n  end\nend\n\nclass Product < Resources::Relation[:service]\n  associate do\n    has_many :line_items\n  end\nend\n\n# Query for high-value orders with specific product categories\nresult = Order.new(context: context)\n  .join(relation: :customer)\n  .join(relation: :line_items)\n  .join(relation: { line_items: :product })\n  .where(total_amount: { gt: 1000 })\n  .where(customer: { loyalty_tier: 'gold' })\n  .where(line_items: { product: { category: ['electronics', 'appliances'] } })\n  .order(created_at: :desc)\n  .limit(20)\n  .to_a\n```\n### 2. Cross-Adapter Operations\n\n```ruby\nclass User < Resources::Relation[:sql]\n  associate do\n    has_many :orders\n  end\nend\n\nclass Order < Resources::Relation[:sql]\n  associate do\n    belongs_to :user\n    has_many :line_items\n  end\nend\n\nclass Product < Resources::Relation[:service]\n  associate do\n    has_many :line_items\n  end\nend\n\n# Fetch users with their orders and associated product details\nresult = User.new(context: context)\n  .join(relation: :orders)\n  .join(relation: { orders: :line_items })\n  .join(relation: { orders: { line_items: :product } })\n  .where(orders: { status: 'completed' })\n  .where(orders: { line_items: { product: { in_stock: true } } })\n  .select(\n    :id,\n    :name,\n    orders: [:id, :total_amount],\n    products: [:id, :name, :price]\n  )\n  .to_a\n```\n\n## Next Steps: Mapping and Composing with Schemas\n\nTo further enhance the efficiency and type safety of our library, the next major development step is to implement mapping and composition of items using schemas. This addition will bring several benefits:\n\n1. **Reduced Iterations**: By defining schemas for our data structures, we can avoid unnecessary array iterations when processing query results. This will lead to improved performance, especially for large datasets.\n\n2. **Type Safety**: Schemas will provide a way to ensure that the data conforms to expected types and structures, catching potential issues early in the development process.\n\n3. **Automatic Transformations**: With schemas in place, we can automatically transform data between different representations (e.g., database records to domain objects) without manual mapping.\n\n4. **Composition**: Schemas will allow for easy composition of complex data structures from simpler components, facilitating the creation of rich, nested data models.\n\nHere's a conceptual example of how this might look:\n\n```ruby\nclass UserSchema < Resources::Schema\n  attribute :id, Types::Integer\n  attribute :name, Types::String\n  attribute :email, Types::String.constrained(format: /\\A[\\w+\\-.]+@[a-z\\d\\-]+(\\.[a-z\\d\\-]+)*\\.[a-z]+\\z/i)\n  attribute :orders, Types::Array.of(OrderSchema)\nend\n\nclass OrderSchema < Resources::Schema\n  attribute :id, Types::Integer\n  attribute :total_amount, Types::Decimal\n  attribute :line_items, Types::Array.of(LineItemSchema)\nend\n\nclass LineItemSchema < Resources::Schema\n  attribute :id, Types::Integer\n  attribute :product_id, Types::Integer\n  attribute :quantity, Types::Integer\n  attribute :price, Types::Decimal\nend\n\n# Usage with automatic mapping\nusers_with_orders = User.new(context: context)\n  .join(relation: { orders: :line_items })\n  .map_to(UserSchema)\n  .to_a\n\n# The result would be an array of UserSchema objects with nested OrderSchema and LineItemSchema objects\n```\n\nBy implementing this schema-based approach, we can significantly reduce the amount of manual data transformation code, improve performance, and enhance the overall robustness of applications built with the Resources library.\n"},{"kind":2,"language":"ruby","value":"define_method :test do |(...)|\n  send(:bot, *)\nend\n\n\ndef bot(...)\nputs ...\nend\n\ntest('asdfsdfasdf')\n"},{"kind":2,"language":"ruby","value":"class B\n  def self.inherited(subclass)\n    super\n    \n    puts subclass\n\n    TracePoint.new(:end) do |tp|\n      if tp.self == subclass\n        puts subclass\n        tp.disable\n      end\n    end.enable\n  end\nend\n\nclass A < B\nend\n\nclass C < A\n\nend\nclass D < C \n  \nend\n\n"},{"kind":1,"language":"markdown","value":""},{"kind":2,"language":"ruby","value":"class Graph\n  def join(left, right, join_keys:, type:)\n    right_node = self.class.new(relation: right, meta: { join_keys:, type: })\n    left.add_node(right_node)\n  end\n\n  def join_to(right, join_keys:, type:)\n    join(self, right, join_keys:, type:)\n  end\n\n  def add_node(node)\n   with(nodes: nodes + [node])\n  end\n\n  def with(**new_options)\n    self.class.new(**options, **new_options)\n  end\n\n  def joins(*args, type: :inner)\n    JoinRelationsVisitor.visit(self, args, type)\n  end\n\n\n  class JoinRelationsVisitor\n    def self.visit(graph, args, type)\n      direct_nodes = args\n    end\n  end\n\nend"},{"kind":2,"language":"ruby","value":"def joins(*args)\n  args.reduce([]) do |acc, path|\n    case path\n    when Hash\n      [*acc, path.to_a]\n    end\n    acc << [left, right]\n  end\nend"},{"kind":2,"language":"ruby","value":"class Graph\n  attr_reader :data, :nodes\n\n  def initialize(data, nodes=[])\n    @data = data\n    @nodes = nodes\n  end\n\n  def compose(*data)\n    data.map do |item|\n      case item\n      when Hash\n        item.map { |key, value| Graph.new(key).compose(value) }\n      when Array\n        item.map(&method(:compose))\n      when Symbol\n        Graph.new(item)\n      end\n    end.flatten.then(&method(:with_nodes))\n  end\n\n  def add_node(node)\n    with_nodes([*nodes, Graph.new(node)])\n  end\n\n  def with_nodes(nodes)\n    self.class.new(data, nodes)\n  end\n\n  def to_s\n    \"#{left} #{right}\"\n  end\n\n  # def resolve\n  #   if left\n  #     left.call(right.call())\n  #   else\n  #     right.call\n  #   end\n  # end\n\n  # def call\n  #   right.map(&call)\n  # end\nend\n\nGraph.new(:parent).compose(:a, :j, b: [:c, :d], e: {f: [{g: :h}]}).inspect\n\n# def test(*args)\n#   puts \"Args class: #{args.class}: #{args}\"\n# end\n\n# test([:b, [:c, :d]], [:e, {:f=>[{:g=>:h}]}])\n"},{"kind":1,"language":"markdown","value":""},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":"test({b: [:c, :d], e: {f: [{g: :h}]}}.to_a)\n"}]