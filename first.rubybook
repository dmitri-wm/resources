[{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'set'\nrequire 'objspace'\nrequire 'concurrent'\n\ndef run_benchmark(x)\n  results = {}\n  memory_usage = {}\n  \n  Benchmark.bm(20) do |bm|\n    hash = Hash.new\n    set = Set.new\n    weak_map = ObjectSpace::WeakMap.new\n    concurrent_map = Concurrent::Map.new\n\n    # Benchmark and measure memory for each data structure\n    [\n      [:hash, hash], [:set, set], [:weak_map, weak_map], [:concurrent_map, concurrent_map]\n    ].each do |name, structure|\n      GC.start # Force garbage collection before measurement\n      initial_memory = ObjectSpace.memsize_of(structure)\n\n      results[:\"#{name}_write\"] = bm.report(\"#{name.to_s.capitalize} write:\") do\n        x.times do |i|\n          case structure\n          when Set\n            structure.add(i)\n          else\n            structure[i] = i\n          end\n        end\n      end\n\n      results[:\"#{name}_read\"] = bm.report(\"#{name.to_s.capitalize} read:\") do\n        x.times do |i|\n          case structure\n          when Set\n            structure.include?(i)\n          else\n            structure.key?(i)\n          end\n        end\n      end\n\n      GC.start # Force garbage collection after operations\n      final_memory = ObjectSpace.memsize_of(structure)\n      memory_usage[name] = final_memory - initial_memory\n    end\n  end\n\n  puts \"\\nResults Table:\"\n  puts \"| Data Structure | Read (ops/s) | Write (ops/s) | Memory Usage (bytes) |\"\n  puts \"|----------------|--------------|---------------|----------------------|\"\n  [\n    [\"Hash\", :hash_read, :hash_write, :hash],\n    [\"Set\", :set_read, :set_write, :set],\n    [\"WeakMap\", :weak_map_read, :weak_map_write, :weak_map],\n    [\"ConcurrentMap\", :concurrent_map_read, :concurrent_map_write, :concurrent_map]\n  ].each do |name, read_key, write_key, mem_key|\n    read_ops = (x / results[read_key].total).round(2)\n    write_ops = (x / results[write_key].total).round(2)\n    mem_usage = memory_usage[mem_key]\n    puts \"| #{name.ljust(14)} | #{read_ops.to_s.ljust(12)} | #{write_ops.to_s.ljust(13)} | #{mem_usage.to_s.ljust(20)} |\"\n  end\nend\n\nrun_benchmark(10_000)"},{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'json'\nrequire 'oj'\n\ndef build_complex_hash(depth = 3)\n  {\n    name: \"Person#{rand(1000)}\",\n    age: rand(18..80),\n    address: {\n      street: \"#{rand(1000)} Main St\",\n      city: [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      country: [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      postal_code: \"#{rand(10000..99999)}\"\n    },\n    hobbies: [\n      {\n        name: \"Reading\",\n        years_practiced: rand(1..20),\n        skill_level: rand(1..10)\n      },\n      {\n        name: \"Cycling\",\n        years_practiced: rand(1..15),\n        skill_level: rand(1..10)\n      },\n      {\n        name: \"Cooking\",\n        years_practiced: rand(1..10),\n        skill_level: rand(1..10)\n      }\n    ],\n    metadata: {\n      created_at: Time.now - rand(10000000),\n      updated_at: Time.now,\n      version: \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      tags: [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    },\n    friends: depth > 0 ? [build_complex_hash(depth - 1), build_complex_hash(depth - 1)] : []\n  }\nend\n\nAddress = Data.define(:street, :city, :country, :postal_code)\nHobby = Data.define(:name, :years_practiced, :skill_level)\nMetadata = Data.define(:created_at, :updated_at, :version, :tags)\nPerson = Data.define(:name, :age, :address, :hobbies, :metadata, :friends)\n\nAddressStruct = Struct.new(:street, :city, :country, :postal_code)\nHobbyStruct = Struct.new(:name, :years_practiced, :skill_level)\nMetadataStruct = Struct.new(:created_at, :updated_at, :version, :tags)\nPersonStruct = Struct.new(:name, :age, :address, :hobbies, :metadata, :friends)\n\nclass Auto\n  def initialize(attributes={})\n    attributes.each do |key, value|\n      instance_variable_set(\"@#{key}\", value)\n\n      define_singleton_method(key) do\n        instance_variable_get(\"@#{key}\")\n      end\n    end\n  end\nend\n\ndef build_data_object(depth = 3)\n  Person.new(\n    \"Person#{rand(1000)}\",\n    rand(18..80),\n    Address.new(\n      \"#{rand(1000)} Main St\",\n      [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      \"#{rand(10000..99999)}\"\n    ),\n    [\n      Hobby.new(\"Reading\", rand(1..20), rand(1..10)),\n      Hobby.new(\"Cycling\", rand(1..15), rand(1..10)),\n      Hobby.new(\"Cooking\", rand(1..10), rand(1..10))\n    ],\n    Metadata.new(\n      Time.now - rand(10000000),\n      Time.now,\n      \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    ),\n    depth > 0 ? [build_data_object(depth - 1), build_data_object(depth - 1)] : []\n  )\nend\n\ndef build_struct_object(depth = 3)\n  PersonStruct.new(\n    \"Person#{rand(1000)}\",\n    rand(18..80),\n    AddressStruct.new(\n      \"#{rand(1000)} Main St\",\n      [\"New York\", \"London\", \"Tokyo\", \"Paris\"].sample,\n      [\"USA\", \"UK\", \"Japan\", \"France\"].sample,\n      \"#{rand(10000..99999)}\"\n    ),\n    [\n      HobbyStruct.new(\"Reading\", rand(1..20), rand(1..10)),\n      HobbyStruct.new(\"Cycling\", rand(1..15), rand(1..10)),\n      HobbyStruct.new(\"Cooking\", rand(1..10), rand(1..10))\n    ],\n    MetadataStruct.new(\n      Time.now - rand(10000000),\n      Time.now,\n      \"1.#{rand(0..9)}.#{rand(0..99)}\",\n      [\"tag1\", \"tag2\", \"tag3\"].sample(2)\n    ),\n    depth > 0 ? [build_data_object(depth - 1), build_data_object(depth - 1)] : []\n  )\nend\n\ndef run_benchmark(iterations)\n  results = {\n    creation: {},\n    serialization: {},\n    deserialization: {}\n  }\n\n  Benchmark.bm(25) do |bm|\n    # Object creation benchmarks\n    results[:creation][:complex_hash] = bm.report(\"Create complex hash:\") do\n      iterations.times { build_complex_hash }\n    end\n\n    results[:creation][:data_object] = bm.report(\"Create Data object:\") do\n      iterations.times { build_struct_object }\n    end\n\n    # Pre-generate objects and strings for other benchmarks\n    complex_hash = build_complex_hash\n    data_object = build_struct_object\n    \n    json_hash_string = JSON.generate(complex_hash)\n    oj_hash_string = Oj.dump(complex_hash,  mode: :object)\n    oj_data_string = Oj.dump(data_object, mode: :object)\n    marshal_hash_string = Marshal.dump(complex_hash)\n    marshal_data_string = Marshal.dump(data_object)\n    json_data_string = oj_data_string\n\n\n    # Serialization benchmarks\n    results[:serialization][:json_hash] = bm.report(\"JSON.generate(hash):\") do\n      iterations.times { JSON.generate(complex_hash) }\n    end\n\n    results[:serialization][:oj_hash] = bm.report(\"Oj.dump(hash):\") do\n      iterations.times { Oj.dump(complex_hash) }\n    end\n\n    results[:serialization][:marshal_hash] = bm.report(\"Marshal.dump(hash):\") do\n      iterations.times { Marshal.dump(complex_hash) }\n    end\n\n    results[:serialization][:json_data] = bm.report(\"JSON.generate(Data.object):\") do\n      iterations.times { JSON.generate(data_object) }\n    end\n\n    results[:serialization][:oj_data] = bm.report(\"Oj.dump(Data.object):\") do\n      iterations.times { Oj.dump(data_object) }\n    end\n\n    results[:serialization][:marshal_data] = bm.report(\"Marshal.dump(Data.object):\") do\n      iterations.times { Marshal.dump(data_object) }\n    end\n\n    # Deserialization benchmarks\n    results[:deserialization][:json_hash] = bm.report(\"JSON.parse(hash):\") do\n      iterations.times { JSON.parse(json_hash_string) }\n    end\n\n    results[:deserialization][:oj_hash] = bm.report(\"Oj.load(hash):\") do\n      iterations.times { Oj.load(oj_hash_string,  mode: :object) }\n    end\n\n    results[:deserialization][:marshal_hash] = bm.report(\"Marshal.load(hash):\") do\n      iterations.times { Marshal.load(marshal_hash_string) }\n    end\n\n    results[:deserialization][:json_data] = bm.report(\"JSON.parse(Data.object):\") do\n      iterations.times { JSON.parse(json_data_string) }\n    end\n\n    results[:deserialization][:oj_data] = bm.report(\"Oj.load(Data.object):\") do\n      iterations.times { Oj.load(oj_data_string,  mode: :object) }\n    end\n\n    results[:deserialization][:marshal_data] = bm.report(\"Marshal.load(Data.object):\") do\n      iterations.times { Marshal.load(marshal_data_string) }\n    end\n  end\n\n  print_results(results, iterations)\nend\n\ndef print_results(results, iterations)\n  [:creation, :serialization, :deserialization].each do |category|\n    puts \"\\n#{category.to_s.capitalize} Results:\"\n    puts \"| Method | Operations/second |\"\n    puts \"|--------|-------------------|\"\n    results[category].each do |key, result|\n      ops_per_second = (iterations / result.total).round(2)\n      puts \"| #{key.to_s.ljust(20)} | #{ops_per_second.to_s.ljust(17)} |\"\n    end\n  end\nend\n\nrun_benchmark(1000)"},{"kind":2,"language":"ruby","value":"class Auto\n  def initialize(attributes={})\n    attributes.each do |key, value|\n      value = Auto.new(value) if value.is_a?(Hash)\n      value = value.map { |v| v.is_a?(Hash) ? Auto.new(v) : v } if value.is_a?(Array)\n      instance_variable_set(\"@#{key}\", value)\n\n      define_singleton_method(key) do\n        instance_variable_get(\"@#{key}\")\n      end\n    end\n  end\nend\n\ndata = {\n  name: \"John\",\n  age: 30,\n  address: {\n    street: \"123 Main St\",\n    city: \"Anytown\"\n  },\n  hobbies: [\n    { name: \"reading\", years: 10 },\n    { name: \"cycling\", years: 5 }\n  ]\n}\n\nauto = Auto.new(data)\n\nputs auto.name  # \"John\"\nputs auto.age   # 30\nputs auto.address.street  # \"123 Main St\"\nputs auto.hobbies[0].name  # \"reading\"\n\n# Convert back to hash\nhash = auto.to_h\nputs hash  # Prints the entire hash structure"},{"kind":2,"language":"ruby","value":""},{"kind":2,"language":"ruby","value":"def transform_keys(obj, transform_map)\n  return obj if transform_map.nil?\n  puts \"obj: #{obj}, transform_map: #{transform_map}\"\n  case obj\n  when Hash\n    obj.each_with_object({}) do |(key, value), result|\n      new_key = transform_map[key] || key\n      if new_key.is_a?(Symbol)\n        result[new_key] = value\n      else\n        result[key] = transform_keys(value, transform_map[key])\n      end\n    end\n  when Array\n    obj.map { |item| transform_keys(item, transform_map) }\n  else\n    obj\n  end\nend\nobj = {\n  item_type: { id: [\"change_event_line_item\"] },\n  with_commitment: [{ contract_line_item_id: [370, 374]}, {none: true}, {pco_line_item_id: :lol}, {some_test: :bot }]\n\n}\n\nts_keys = {\n  change_event_line_item: :id,\n  with_change_event_ids: :event_id,\n  with_commitment: {\n    contract_line_item_id: :commitment_contract_line_item_id,\n    pco_line_item_id: :commitment_potential_change_order_line_item_id,\n    none: :without_committed_cost\n  }\n}.freeze\n\nresult = transform_keys(obj, ts_keys)\n"},{"kind":2,"language":"ruby","value":"   def commitment(values, scope)\n      puts \"commitment: #{scope}, values: #{values}\"\n   end\n\n   def query_on_scope_field?(filter)\n    puts \"query_on_scope_field?: #{filter}\"\n    puts     filter.class\n\n    filter == :commitment\n   end\n\n   def use_service_method?(filter)\n    puts \"use_service_method?: #{filter}\"\n    respond_to?(filter, true)\n   end\n\n   def service_method(scope, (field, values))\n    send(field, values, scope)\n   end\n\n   def run_query_on_scope(scope, *args)\n    puts \"run_query_on_scope: #{scope}, #{args}\"\n   end\n\n   pr = proc do |*args|\n                puts  \"args: #{args}\"\n                case args\n                in [_, [Symbol => filter, _]] if query_on_scope_field?(filter) then run_query_on_scope(*args)\n                in [_, [Symbol => filter, _]] if use_service_method?(filter) then service_method(*args)\n                in [_, [Hash, _]] then filter_to_query[*args]\n                else raise ArgumentError, \"Unknown filter: #{filter}\"\n                end\n              end\n\n              {commitment: [line_item: [1,2,3,34]]}.reduce(1, &pr)\n\n              pr.call()\n\n"},{"kind":2,"language":"ruby","value":"require 'securerandom'\nrequire 'date'\nkeys = [:\"change_event.number_title\", :\"change_event.title\", :\"change_event.number\", :\"change_event.status\", :\"change_event.scope\", :\"change_event.type\", :\"change_event.change_reason\", :\"change_event.origin.name\", :\"change_event.created_at\", :\"change_event.created_by\", :item_type, :\"budget_code.description\", :description, :\"vendor.name\", :\"contract.name\", :unit_of_measure, :aging, :\"revenue.quantity\", :\"revenue.unit_cost\", :\"revenue.rom\", :\"revenue.prime_potential_change_order.amount\", :\"revenue.prime_potential_change_order.title\", :\"revenue.stage.display_value\", :\"revenue.days_in_stage\", :\"revenue.stage_status\", :\"revenue.in_status_since\", :\"revenue.latest_price\", :\"cost.quantity\", :\"cost.unit_cost\", :\"cost.rom\", :\"cost.request_for_quote.amount\", :\"cost.request_for_quote.title\", :\"cost.commitment.amount\", :\"cost.commitment.title\", :\"cost.non_commitment\", :\"cost.stage.display_value\", :\"cost.days_in_stage\", :\"cost.stage_status\", :\"cost.in_status_since\", :\"cost.latest_cost\", :over_under, :\"budget.quantity\", :\"budget.unit_cost\", :\"budget.rom\", :\"budget.budget_change.amount\", :\"budget.stage.display_value\", :\"budget.days_in_stage\", :\"budget.stage_status\", :\"budget.in_status_since\", :\"budget.impact_amount\", :\"budget.modification.amount\", :\"production_quantity.quantity\", :\"production_quantity.unit_of_measure\"]\nCeliStruct = Data.define(*keys)\n\ndef generate_random_value(key)\n  case key.to_s\n  when /number|quantity|amount|rom|days/\n    rand(1..1000)\n  when /cost|price/\n    rand(100.0..10000.0).round(2)\n  when /_at$/\n    DateTime.now - rand(365)\n  when /status|type|scope|reason|stage/\n    %w[New In-Progress Completed Approved Rejected].sample\n  when /name|title|description/\n    SecureRandom.alphanumeric(10)\n  else\n    SecureRandom.uuid\n  end\nend\n\n# Create a hash with random values for each key\nrandom_data = -> { keys.to_h { |key| [key, generate_random_value(key)] } }\n\n# Create an instance of CeliStruct with the random data\ndata = (0..87_000).map { CeliStruct.new(**random_data.call) }; 0\n"},{"kind":2,"language":"ruby","value":"require 'benchmark'\nrequire 'json'\nrequire 'oj'\n\ndef create_flat_data(depth = 3, prefix = '')\n  result = {}\n  (1..5).each do |i|\n    key = \"#{prefix}key#{i}\"\n    result[key] = \"value#{i}\"\n    if depth > 0\n      result.merge!(create_flat_data(depth - 1, \"#{key}.\"))\n    end\n  end\n  result\nend\n\ndef create_nested_data(depth = 3)\n  result = {}\n  (1..5).each do |i|\n    key = \"key#{i}\"\n    if depth > 0\n      result[key] = create_nested_data(depth - 1)\n    else\n      result[key] = \"value#{i}\"\n    end\n  end\n  result\nend\n\ndef flat_to_nested(flat_data)\n  result = {}\n  flat_data.each do |key, value|\n    parts = key.to_s.split('.')\n    current = result\n    parts[0...-1].each do |part|\n      current[part] = {} unless current[part].is_a?(Hash)\n      current = current[part]\n    end\n    current[parts.last] = value\n  end\n  result\nend\n\ndef nested_to_flat(nested_data, prefix = '')\n  result = {}\n  nested_data.each do |key, value|\n    new_key = prefix.empty? ? key : \"#{prefix}.#{key}\"\n    if value.is_a?(Hash)\n      result.merge!(nested_to_flat(value, new_key))\n    else\n      result[new_key] = value\n    end\n  end\n  result\nend\n\nflat_data = create_flat_data\nnested_data = create_nested_data\n\nn = 10_000\n\nBenchmark.bm(20) do |x|\n  x.report(\"Flat merge:\") { n.times { flat_data.merge(create_flat_data) } }\n  x.report(\"Nested merge:\") { n.times { nested_data.merge(create_nested_data) } }\n  \n  x.report(\"Flat to nested:\") { n.times { flat_to_nested(flat_data) } }\n  x.report(\"Nested to flat:\") { n.times { nested_to_flat(nested_data) } }\n  \n  x.report(\"Flat deep copy:\") { n.times { Oj.load(Oj.dump(flat_data)) } }\n  x.report(\"Nested deep copy:\") { n.times { Oj.load(Oj.dump(nested_data)) } }\n  \n  x.report(\"Flat serialize:\") { n.times { Oj.dump(flat_data) } }\n  x.report(\"Nested serialize:\") { n.times { \n  Oj.dump(nested_data) } }\nend"}]